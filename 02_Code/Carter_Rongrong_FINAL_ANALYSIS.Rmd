---
title: "Statistical Trend Analysis of Great Lakes Ice Cover Changes (1973 to 2025)"
author: "Rongrong Qian & Carter Vonderahe"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    theme: journal
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)

# load libraries
library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(stringr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(forecast)
```

# Introduction
Ice cover on the Great Lakes significantly influences regional societal benefits, including hydropower generation, commercial shipping, and the fishing industry. The extent and duration of this ice cover fluctuate annually, and long term reductions linked to global warming are a key concern for scientists at the NOAA Great Lakes Environmental Research Laboratory (GLERL). Monitoring and analyzing lake ice is essential as it impacts regional climate patterns, lake water levels, water temperature structures, and vital ecological processes such as spring plankton blooms.

The goal of this report is to provide a comprehensive inferential statistical analysis examining systemic changes and trends in the annual ice cover on the Great Lakes over the past 50 years. This analysis utilizes daily percent ice cover data, derived from USNIC and CIS records, to identify and quantify potential long term shifts in this critical environmental indicator.

---

# Methods

## Data 

### Data Description

This analysis utilizes the Great Lakes daily ice cover dataset provided by the NOAA Great Lakes Environmental Research Laboratory (GLERL). The dataset comprises daily observations spanning the ice seasons (November 10 to June 5) from 1973 to 2025. The data entries represent the percentage of total ice cover for the Great Lakes, calculated from gridded ASCII files originally sourced from the U.S. National Ice Center (USNIC) and the Canadian Ice Service (CIS). In the data matrix, columns correspond to individual years, and rows correspond to the day of the year. 

### Data Preparation

The raw dataset contained missing values (NAs) exhibiting distinct patterns, which were addressed as follows:
```{r data_cleaning}
# read and clean column names
raw0 <- read_csv("greatlakesicedata.csv", show_col_types = FALSE)
nm   <- names(raw0)
nm[1] <- "day_mon"
year_cols <- str_extract(nm[-1], "\\b\\d{4}\\b")
keep     <- c(TRUE, !is.na(year_cols))
raw      <- raw0[, keep, drop = FALSE]
names(raw) <- c("day_mon", year_cols[!is.na(year_cols)])
# create day_mon factor levels
day_levels <- format(
  seq(from = as.Date("2020-11-10"),
      to   = as.Date("2021-06-05"),
      by   = "day"),
  "%e-%b"
) %>%  stringr::str_trim()

# pivot longer format
ice_clean <- raw %>%
  mutate(
    row_id  = row_number(),
    day_mon = str_trim(day_mon),
    # unify possible "Feb-29" to "29-Feb"
    day_mon = if_else(day_mon == "Feb-29", "29-Feb", day_mon)
  ) %>%
  pivot_longer(-c(day_mon, row_id),
               names_to  = "year",
               values_to = "ice") %>%
  mutate(
    year  = as.integer(year),
    ice   = suppressWarnings(as.numeric(ice)),
    date  = as.Date(paste0(day_mon, "-", year), format = "%d-%b-%Y"),
    month = factor(
      lubridate::month(date),
      levels = c(11, 12, 1, 2, 3, 4, 5, 6),
      labels = month.abb[c(11, 12, 1, 2, 3, 4, 5, 6)]
    ),
    day      = day(date),
    day_mon  = factor(day_mon, levels = day_levels, ordered = TRUE)
  ) %>%
  arrange(year, row_id) %>%
  select(date, year, month, day, day_mon, row_id, ice)
```

**1. Leap year adjustment:**

To ensure consistent matrix dimensions across all years (uniform 365-day series), the handling of February 29 needs to be standardized. In leap years where February 29 contained valid data, the value for February 28 was recalculated as the mean of the observations from February 28 and February 29. The row corresponding to February 29 was then removed from the dataset. In non-leap years, the "NA" placeholder for February 29 was simply removed. February 29 was the only instance of missing values existing in the middle of a cold season (see Appendix A).

**2. Leading and Trailing Missing Values:**

A significant portion of missing data was concentrated at the beginning (starting November 10) and the end (approaching June 5) of the ice seasons. These missing entries likely represent "latent zeros," indicating periods where ice cover was negligible due to warmer seasonal temperatures. Additionally, missing values in the earlier years of the dataset may be attributed to limitations in historical remote sensing capabilities or monitoring protocols, where recording only commenced once significant ice formation was visually confirmed. So, these missing values were imputed using a conditional strategy to distinguish between true absence of ice and unrecorded data. This method utilized a defined threshold, $\tau_0$.

* True Zeros: If the adjacent observed value (the first valid data point for leading gaps or the last valid point for trailing gaps) was less than or equal to $\tau_0$, the entire run of missing values was treated as "true zeros" (0% ice cover).
* Linear Extrapolation: If the adjacent observed value exceeded $\tau_0$, linear extrapolation were applied using the contiguous block of observed data immediately next to the gap.
  * Leading gaps: A linear model was fitted to the first contiguous block of data, and values were back-projected into the gap.
  * Trailing gaps: A linear model was fitted to the last contiguous block, and values were projected forward.
  
* Constraints: The extrapolation followed a specific stopping rule: moving outward from the observed data, as soon as a predicted value dropped below 0, that day and all remaining outer days in the gap were set to 0. Finally, all predicted values were clamped to a range of [0, 100] to prevent unrealistic values.

Exploratory analysis revealed a distinct shift in data quality around 1993, so the imputation strategy was applied only to years prior to 1993, with the exception of February 29, which was combined with February 28 as described above. Any remaining missing values in these later years were set to 0, assuming that monitoring practices improved.

```{r imputation_code}
# Imputation 
# threshold for "close to zero" (%)
tau0 <- 5

feb28_idx <- 111L
feb29_idx <- 112L


impute_year <- function(x, y, tau0 = 5, feb29_idx = NA_integer_,
                        win_lead = 20, win_trail = 20) {
  # x: row_id (1..n) for one year
  # y: daily ice % (may contain NA) for the same year
  n  <- length(y)
  y2 <- y
  # keep values in [0, 100]
  clamp <- function(v) pmax(0, pmin(100, v))

  # Fill Feb 29 if NA and has neighbors
  if (!is.na(feb29_idx) && feb29_idx >= 2L && feb29_idx <= n - 1L &&
      is.na(y2[feb29_idx])) {
    a <- y2[feb29_idx - 1L]
    b <- y2[feb29_idx + 1L]
    y2[feb29_idx] <-
      if (is.finite(a) && is.finite(b)) (a + b) / 2 else
      if (is.finite(a)) a else
      if (is.finite(b)) b else NA_real_
  }
  # indices of non-missing observations
  obs <- which(!is.na(y2))
  if (!length(obs)) return(y2) 

  # leading gap (before first observed)
  k1 <- obs[1L] # first observed index
  if (k1 > 1L) {
    s <- 1L # start index of leading gap
    e <- k1 - 1L # end index of leading gap

   # observed indices AFTER the gap
    obs_after <- obs[obs >= k1]
    # use only the first 'win_lead' observed days to fit the line
    use_idx <- obs_after[seq_len(min(length(obs_after), win_lead))]

    if (length(use_idx) >= 2L) {
      fit <- lm(y ~ x, data = data.frame(
        y = y2[use_idx],
        x = x[use_idx]
      ))
      preds <- as.numeric(predict(fit, newdata = data.frame(x = x[s:e])))
      # enforce physical bounds: 0 <= preds <= first observed value
      upper <- y2[k1]
      preds <- clamp(preds)
      preds[preds > upper] <- upper
      preds[preds < 0]     <- 0
      y2[s:e] <- preds
    } else {
      # fallback: simple linear ramp 0 -> first observed
      y2[s:e] <- clamp(seq(0, y2[k1], length.out = e - s + 1L))
    }
  }

  # trailing gap
  k2 <- obs[length(obs)]
  if (k2 < n) {
    s <- k2 + 1L
    e <- n

    # observed indices BEFORE the gap
    obs_before <- obs[obs <= k2]
    # use only the last 'win_trail' observed days to fit the line
    use_idx <- tail(obs_before, n = min(length(obs_before), win_trail))

    if (length(use_idx) >= 2L) {
      fit <- lm(y ~ x, data = data.frame(
        y = y2[use_idx],
        x = x[use_idx]
      ))
      preds <- as.numeric(predict(fit, newdata = data.frame(x = x[s:e])))
      
      # enforce physical bounds: 0 <= preds <= last observed value
      upper <- y2[k2]
      preds <- clamp(preds)
      preds[preds > upper] <- upper
      preds[preds < 0]     <- 0

      y2[s:e] <- preds
    } else {
      # fallback: simple ramp last observed -> 0
      y2[s:e] <- clamp(seq(y2[k2], 0, length.out = e - s + 1L))
    }
  }

  y2
}

# years before 1993: run imputation
imputed_pre1993 <- ice_clean %>%
  filter(year < 1993) %>%
  group_by(year) %>%
  arrange(row_id, .by_group = TRUE) %>%
  mutate(
    ice_imp = impute_year(
      x         = row_id,
      y         = ice,
      tau0      = tau0,
      feb29_idx = feb29_idx
    )
  ) %>%
  ungroup() %>% 
  filter(row_id != feb29_idx)  # remove Feb-29 row

# years 1993 and later: keep original values but
# combine Feb 28 & Feb 29 by mean into Feb 28
post1993 <- ice_clean %>%
  filter(year >= 1993) %>%
  mutate(ice_imp = ice) %>%
  group_by(year) %>%
  mutate(
    # mean of Feb-28 and Feb-29 in this year
    feb_mean = mean(
      ice_imp[row_id %in% c(feb28_idx, feb29_idx)],
      na.rm = TRUE)
    ) %>%
  ungroup() %>%
  mutate(
    # 1) overwrite Feb-28 (row 111) with that mean
    ice_imp = if_else(row_id == feb28_idx, feb_mean, ice_imp),
    # 2) set all remaining NA to 0
    ice_imp = if_else(is.na(ice_imp), 0, ice_imp)
  ) %>%
  # 3) drop Feb-29 row (row 112)
  filter(row_id != feb29_idx) %>%
  select(-feb_mean)

# combine and keep row_id ordering
imputed <- bind_rows(imputed_pre1993, post1993) %>%
  arrange(year, row_id)
```


## Assumptions

### Missing Data Thresholding

Missing values at the beginning and end of the ice season are treated as "latent zeros" or imputed based on adjacent data trends. For this analysis, the threshold $\tau_0$ is assumed to be 5% ice cover$^{[13]}$. 

### Assumptions for Trend Analysis

Although the Theil-Sen estimator is nonparametric and does not require the strict normality assumptions of ordinary least squares regression, valid inference relies on the following assumptions:

**1. Monotonic Trend Structure**

The test is designed to detect monotonic trends, meaning the variable consistently increases or decreases over time. It is assumed that the underlying trend does not exhibit complex oscillations or multiple regime shifts.

**2. Assessment of Serial Dependence**

The randomization test for trend analysis (discussed in detail in Section 2.3.2) operates under the null hypothesis of exchangeability. This assumption states that if no temporal trend exists, all permutations of the data's time order are equally plausible. However, because this series arises from a natural system governed by large scale climatic processes, this assumption may be compromised by serial dependence (autocorrelation). To evaluate this potential violation, the Autocorrelation Function (ACF) of the annual time series is examined. If the ACF reveals weak or insignificant autocorrelation, the exchangeability assumption is considered reasonable, validating the use of a simple random permutation.

**3. Stability of Measurement**

Data collection methods and measurement accuracy are assumed to remain consistent throughout the study period. This ensures that detected trends reflect actual environmental changes rather than artifacts of the measurement process.


## Statistical Methodology

### Annual Ice Cover Metric

The primary response variable for this analysis is the sum of daily ice cover percentages over each ice season (November 10 to June 5) for each year. This metric captures the overall extent and duration of ice cover, providing a comprehensive measure of seasonal ice dynamics. The estimated cumulative ice cover index Area Under the Curve (AUC) denoted as $AUC_y$ is calculated as the sum of daily percentages:

$$
AUC_y = \sum_{t=1}^{n_y} I_{y,t}
$$

where $I_{y,t}$ represents the ice cover percentage on day $t$ of year $y$.

```{r auc_calculation, echo=FALSE}
# calculate AUC per year
auc_data <- imputed %>%
  group_by(year) %>%
  summarize(
    AUC = sum(ice_imp, na.rm = TRUE),
    .groups = "drop"
  )
```

### Trend Analysis and Inference

To quantify long-term changes in annual ice cover, the response $(AUC_y)$ is analyzed as a time series indexed by year $y$. In this report, non-parametric methods are employed for both estimation and inference.

**1. Trend Estimation**

The magnitude of the linear trend is estimated using the Theil-Sen slope estimator. This method computes the slopes for all possible pairs of years $i$ and $j$ where $i$ is less than $j$. The slope between years $i$ and $j$ is

$$s_{ij} = \frac{Y_j - Y_i}{t_j - t_i},$$

where $Y_i$ and $Y_j$ are the annual ice cover metrics for years $i$ and $j$, respectively, and $t_i$ and $t_j$ are the corresponding years. The final slope estimate, denoted as $\hat{\beta}_1$, is defined as the median of these slopes calculated between pairs. This estimator is highly resistant to outliers, making it well suited for hydroclimatic time series. To visualize the trend, a reference line is constructed using $\hat{\beta}_1$ and an intercept $\hat{\beta}_0$, chosen such that the line passes through the median of the observed values.

**2. Statistical Inference via Randomization Test**

The statistical significance of the observed trend is assessed using a randomization test built around the Theil–Sen slope:

- The observed test statistic is the estimated slope $\hat{\beta}_1$ from the actual ordering of years.\
- Under the null hypothesis, the slope of the trend is 0. Therefore, under the null, a given recorded AUC value in the data is equally likely to occur in any year. So, to perform the randomization test, recorded AUC values are randomly permuted to years, and the Theil–Sen slope is recalculated based on this permutation. This process is done 10,000 times to form a null distribution of slopes.\
- The two-sided p-value is obtained as the proportion of permuted slopes whose absolute value is at least as large as the absolute value of the observed slope. A low p-value (< 0.05) indicates that the observed trend is considered statistically significant.

**3. Confidence Interval for the Theil–Sen Slope**

A permutation-based confidence interval was constructed by approximating the distribution of the estimation error using the permuted slopes computed under the null hypothesis ($\beta_1 = 0$). Since the randomization scheme dissociates years from their AUC values, the resulting distribution of slopes is centered at zero. By inverting this null distribution, the 95% confidence interval is formed. Let $q_{0.025}$ and $q_{0.975}$ denote the 2.5th and 97.5th percentiles of these null permuted slopes, respectively. The interval for the true parameter $\beta_1$ is given by: $$[\hat{\beta}_1 - q_{0.975}, \quad \hat{\beta}_1 - q_{0.025}]$$


## Software
All statistical analyses and data visualizations were performed using the `R (version 4.5.1)` within the `RStudio` integrated development environment (version 2025.09.2+418). Data manipulation and cleaning were conducted using the `tidyverse` ecosystem, specifically `dplyr` and `tidyr` for structural reshaping, `readr` for data ingestion, `stringr` for text processing, and `lubridate` for date-time management.

Visualizations were generated using `ggplot2` to ensure consistent aesthetic standards. Time series forecasting and autocorrelation diagnostics were implemented using the `forecast` package. Finally, this report was dynamically generated using `knitr` and `kableExtra` to ensure reproducibility and streamlined table formatting.

---

# Results

## Analysis of Missing Values

```{r na_analysis, echo=FALSE, fig.height=4}
# check NAs
na_summary <- ice_clean %>%
  group_by(year) %>%
  summarize(
    total_days = n(),
    NA_count = sum(is.na(ice)),
    NA_percentage = (NA_count / total_days) * 100
  )

# show NA trend over years
ggplot(na_summary, aes(x = as.integer(year), y = NA_percentage)) +
  geom_line(color = "steelblue") +
  geom_point() +
  labs(x = "", y = "% of NA",
       title = "Figure 1",
       subtitle = "Trend of NA Over Years") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold")
  )
```

Figure 1 illustrates the temporal trend in missing data across the study period (1973–2025). The percentage of missing values for each year was calculated as the ratio of missing days to the total number of days in the ice season ($NA\_percentage = \frac{NA\_count}{total\_days} \times 100$). A clear decreasing trend in missing data is observed over time. In the earlier decades (1970s and 1980s), the proportion of missing values fluctuated significantly, often exceeding 40% to 50%. Conversely, in the most recent decades, the proportion has generally stabilized at lower levels, frequently falling below 20%. This pattern likely reflects improvements in data collection technologies, such as satellite remote sensing, and more consistent monitoring protocols in recent years. The presence of these NAs underscores the importance of the imputation strategies outlined in Section 2.1.2.

```{r imputed_viz, echo=FALSE}
# Start / End / Peak 
# season is the start, end and peak rows
season <- ice_clean %>% 
  group_by(year) %>% 
  summarise(
    start_row = { idx <- which(!is.na(ice)); if (length(idx)) min(idx) else NA_integer_ }, 
    end_row   = { idx <- which(!is.na(ice)); if (length(idx)) max(idx) else NA_integer_ },
    peak_row  = {
      if (all(is.na(ice))) NA_integer_
      else { v <- ifelse(is.na(ice), -Inf, ice); which.max(v) }
    },
    .groups = "drop"
  ) %>% 
  tidyr::drop_na(start_row, end_row)  

season_start <- as.Date("1973-11-10")
season_end   <- as.Date("1974-06-05")

# prepare data for plotting imputed vs original 
imputed_plot <- imputed %>%
  left_join(season, by = "year") %>%
  mutate(
    season_date = season_start + (row_id - 1),
    ice_obs     = if_else(row_id < start_row | row_id > end_row,
                          NA_real_, ice)
  )

selected_years <- c(1973, 1976, 1977, 1980, 1981, 1984)

ggplot(filter(imputed_plot, year %in% selected_years),
       aes(x = season_date)) +
  # grey imputed line on bottom
  geom_line(aes(y = ice_imp, color = "Imputed"),
            linewidth = 0.8, na.rm = TRUE) +
  # blue original line on top, only where observed
  geom_line(aes(y = ice_obs, color = "Original"),
            linewidth = 0.9, na.rm = TRUE) +
  facet_wrap(~ year, ncol = 2) +
  scale_color_manual(
    values = c("Imputed" = "grey70", "Original" = "steelblue"),
    name   = "Data Type"
  ) +
  scale_x_date(
    limits      = c(season_start, season_end),
    date_breaks = "1 month",
    date_labels = "%b"
  ) +
  labs(
    x     = "Date in Season (Nov 10 – Jun 5)",
    y     = "Ice Cover (%)",
    title = "Figure 2",
    subtitle = "Original vs Imputed Ice Cover Data for Selected Years"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold")
  )
 
```

Figure 2 compares original observations (blue) with imputed values (grey) for years exhibiting significant seasonal gaps. The visualizations confirm that the constrained linear extrapolation effectively reconstructs missing tails. By clamping predictions between zero and the adjacent observed value, the method ensures a smooth, physically realistic transition from the ice free season to the recorded data, preserving the continuity of the time series. Also, the imputation decreases abrupt jumps at the start and end of the ice season, enhancing the overall data quality for subsequent trend analyses.

## Assessing Duration and Intensity

```{r start_peak_end, fig.height=4}
# map row -> date
base_start <- as.Date("1973-11-10")
base_end   <- base_start + (nrow(raw) - 1)

season <- season %>%
  mutate(
    start_date = base_start + (start_row - 1),
    end_date   = base_start + (end_row   - 1),
    peak_date  = base_start + (peak_row  - 1)
  )

# prepare observed season data
imputed_startend <- imputed %>%
  mutate(
    is_ice = !is.na(ice_imp) & ice_imp > 0  # TRUE = has ice, FALSE = no ice (0 or NA)
  )
# Build Start / End / Peak (by row), then map row -> date on y using the imputed data
season_imp <- imputed_startend %>%
  group_by(year) %>%
  summarise(
    # start: first day where is_ice goes from FALSE (0) to TRUE (>0)
    start_row_im = {
      idx <- which(is_ice & !dplyr::lag(is_ice, default = FALSE))
      if (length(idx)) min(idx) else NA_integer_
    },
    # end: last day where is_ice goes from TRUE (>0) to FALSE (0)
    end_row_im = {
      idx <- which(is_ice & !dplyr::lead(is_ice, default = FALSE))
      if (length(idx)) max(idx) else NA_integer_
    },
    # peak: max ice within the ice season (only among is_ice == TRUE)
    peak_row_im = {
      if (!any(is_ice)) {
        NA_integer_
      } else {
        v <- ifelse(is_ice, ice_imp, -Inf)
        which.max(v)
      }
    },
    .groups = "drop"
  ) %>%
  tidyr::drop_na(start_row_im, end_row_im) %>%
  arrange(year)

# map row -> date
base_start_im <- as.Date("1973-11-10")
base_end_im   <- base_start_im + (nrow(raw) - 1)

# map observed season rows to dates
season_imp <- season_imp %>%
  mutate(
    start_date_im = base_start + (start_row_im - 1),
    end_date_im   = base_start + (end_row_im   - 1),
    peak_date_im  = base_start + (peak_row_im  - 1)
  )

# range for x-axis
min_year <- min(c(season$year, season_imp$year))
max_year <- max(c(season$year, season_imp$year))

ggplot() +
  # Bottom layer: imputed season band
  geom_ribbon(
    data = season_imp,
    aes(x = year, ymin = start_date_im, ymax = end_date_im),
    fill = "grey50", alpha=0.8, color = NA, na.rm = TRUE
  ) +
  # Top layer: observed season band
  geom_ribbon(
    data = season,
    aes(x = year, ymin = start_date, ymax = end_date),
    fill = "grey85", color = NA, na.rm = TRUE
  ) +
  # Observed peak line and points (on top)
  geom_line(
    data = season,
    aes(x = year, y = peak_date, group = 1),
    color = "steelblue", linewidth = 1
  ) +
  geom_point(
    data = season,
    aes(x = year, y = peak_date),
    color = "steelblue", size = 1.8
  ) +
  scale_x_continuous(
    breaks       = seq(min_year, max_year, by = 5),
    minor_breaks = seq(min_year, max_year, by = 5)
  ) +
  # Reverse y-axis so Nov-10 is at the top and Jun-05 at the bottom
  scale_y_date(
    limits      = c(base_end, base_start),   # reversed
    breaks      = seq(base_start, base_end, by = "1 month"),
    date_labels = "%d-%b",
    expand      = expansion(mult = c(0.01, 0.01))
  ) +
  labs(
    x = "",
    y = "Date (Nov-10 → Jun-05)",
    title    = "Figure 3",
    subtitle = "Duration of Ice Coverage over Time",
    caption = "Light grey = Observed Start–End; Dark grey = Imputed Start–End; Blue = Observed Peak"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold")
  )
```

Figure 3 illustrates ice season phenology, distinguishing between the observed duration (light grey) and the additional coverage recovered through imputation (dark grey). Consistent with the data quality assessment, imputation was exclusively applied to the pre-1993 era, extending the season boundaries in these earlier years to reflect realistic start and end dates. Typically, the ice season spans from late November or December through late April or May. Despite interannual variability in duration, the timing of peak ice cover (blue line) remains largely consistent throughout the study period, centering primarily in late February to mid-March. Extreme cases are observed during years with strong climatic anomalies, most prominently in 1998, 2016, and 2023. These years exhibit drastically shortened seasons and unusually low ice coverage. These anomalies coincide with periods of significantly warmer winter temperatures (associated with strong El Niño events in 1997–1998 and 2015–2016, and record-breaking warmth in 2023), which severely suppressed ice formation and accelerated the melt season.

```{r heatmap_plot, fig.height=5}
### HEAT MAP ###
ggplot() +
  geom_raster(aes(x = year, y = day_mon, fill = ice_imp), data = imputed) +
  # scale_fill_gradient(low = "white",
  #                     high = "navy",
  #                     guide = guide_colorbar(ticks = TRUE, label = TRUE,
  #                                            barheight = .5, barwidth = 8)) +
  scale_fill_viridis_c(option = "mako", direction = -1,
                       guide = guide_colorbar(ticks = TRUE, label = TRUE,
                                              barheight = .5, barwidth = 8)) +
  theme_minimal() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_discrete(breaks = c("1-Dec", "1-Jan", "1-Feb", "1-Mar", "1-Apr", "1-May", "1-Jun"),
                   labels = c("Dec", "Jan", "Feb", "Mar", "Apr", "May", "Jun"),
                   limits = levels(imputed$day_mon)) +
  labs(title = "Figure 4",
       subtitle = "Intensity of Ice Coverage over Time",
       fill = "% Coverage",
       y = NULL,
       x = NULL) +
  theme(
    # text settings
    axis.text = element_text(size = 8),
   
    # legend settings
    legend.position = c(0.5, -0.15),
    legend.direction = "horizontal",
    legend.title = element_text(vjust = 1),
   
    # plot settings
    plot.margin = grid::unit(c(.5, .5, 1.5, .5), "cm"),
    plot.title = element_text(face = "bold")
  )
```

Figure 4 visualizes daily ice intensity after imputation of missing values, where the color gradient transitions from light teal (low cover) to dark purple (high cover). A clear temporal shift is evident: early decades display broad dark bands, whereas recent years feature lighter tones, signaling a reduction in ice coverage. Despite this long-term decline, the seasonal peak consistently remains centered in February and March. Again, the effect of the El Niño events manifests in shorter seasons and unusually low ice cover around the years 1998, 2016, and 2023.


## Trend Estimation & Significance

Prior to computing the Theil-Sen slope, independence of the data points across time is first assessed. From the ACF plot, there is no significant autocorrelation in the AUC time series, so the recorded values of AUC are reasonably independent (see Appendix B).

```{r auc_trend_plot, echo=FALSE}
# calculate Theil-Sen slope
theil_sen_slope <- function(x, y) {
  n <- length(x)
  slopes <- c()
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      if (x[j] != x[i]) {
        slopes <- c(slopes, (y[j] - y[i]) / (x[j] - x[i]))
      }
    }
  }
  median(slopes, na.rm = TRUE)
}

# calculate slope
slope_est <- theil_sen_slope(auc_data$year, auc_data$AUC)
intercept_est <- median(auc_data$AUC) - slope_est * median(auc_data$year)
```

```{r auc_trend_plot_gg, fig.height=4}
# plot AUC time series with trend line
ggplot(auc_data, aes(x = year, y = AUC)) +
  geom_point(color = "steelblue", size = 2) +
  geom_line(color = "steelblue", linewidth = 0.8) +
  geom_abline(slope = slope_est, intercept = intercept_est,
              color = "darkred", linetype = "dashed", linewidth = 1) +
  labs(x = NULL,
       y = "Annual Ice Cover AUC",
       title = "Figure 5",
       subtitle = "Time Series of Annual Ice Cover AUC",
       caption = "Blue = Recorded AUC; Red = Theil-Sen Slope Estimate") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold")
  )
```

Figure 5 displays the temporal evolution of the cumulative ice cover (AUC) from 1973 to 2025. The series is characterized by substantial interannual variability, exhibiting sharp oscillations between high ice and low ice seasons. Prominent peaks are observed in the late 1970s, 1994, and 2014, while prolonged periods of suppressed ice cover become more apparent in the latter half of the record. The observed Theil-Sen slope for the AUC is depicted by the red dashed line in Figure 5, and exhibits a decline over time.

```{r permutation_test, cache=TRUE}
# number of random permutations to generate
n_perm <- 10000

# initialize vectors
TSs <- numeric(n_perm) # theil-sen slopes (these are slopes generated UNDER THE NULL)


### PERMUTATION TEST ###
set.seed(12345) # set seed for reproducibility
for (i in 1:n_perm) {
  
  # randomly permute AUC
  auc_data$AUC_rand <- sample(auc_data$AUC)
  
  # compute TS slope ON AUC_rand
  TSs[i] <- theil_sen_slope(auc_data$year, auc_data$AUC_rand)
}

# compute p-value
p_value <- mean(abs(TSs) > abs(slope_est))
```

```{r confidence_interval, eval=FALSE}
# CI using quantiles of null distribution
slope_est - quantile(TSs, probs = c(0.975, 0.025))
```


```{r, fig.height=3}
ggplot(data.frame(TSs)) +
  geom_histogram(aes(x=TSs),
                 fill = "skyblue",
                 color = "grey50") +
  geom_vline(xintercept = slope_est, color = "darkred") +
  geom_vline(xintercept = abs(slope_est), color = "darkred") +
  annotate(geom = "text", label = "-|Observed Slope|", x = -abs(slope_est), y = 950,
           hjust = -0.05, color = "darkred", fontface = "bold") +
  annotate(geom = "text", label = "|Observed Slope|", x = abs(slope_est), y = 950,
           hjust = 1.05, color = "darkred", fontface = "bold") +
  scale_y_continuous(expand = c(0, 0)) +
  labs(y = NULL,
       x = NULL,
       title = "Figure 6",
       subtitle = "Null Distribution of Permuted Theil-Sen Slopes") +
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    
    plot.title = element_text(face = "bold")
  )
```

Figure 6 displays the distribution of the Theil-Sen slopes computed from the 10,000 random permutations. Notably, the distribution is centered around 0 because the slope is equal to 0 under the null hypothesis. The observed Theil-Sen slope for the AUC is $-47.61$ (95% CI $[-79.24, -16.32]$, $p=0.0024$). At $\alpha = 0.05$, we reject the null hypothesis and have sufficient evidence to conclude that the true trend slope of the percent ice coverage on the Great Lakes is significantly different from 0.

---

# Conclusion

Overall, the results of this study provide strong evidence of a long-term decline in Great Lakes seasonal ice cover from 1973 to 2025. A key limitation of this analysis was the need to impute data at the beginning and end of each ice season. Depending on the method of imputation, the results may vary. However, this analysis carefully addresses the missing data in a reasonable manner, and after applying robust nonparametric methods, the permutation test indicates a statistically significant downward trend in cumulative ice cover. The contraction of the ice season, which is reflected in earlier melt dates, later onset, and reduced peak intensity, underscores the sensitivity of the Great Lakes to climatic warming. These findings highlight the importance of continued monitoring and reinforce the need for adaptive strategies in sectors that depend on ice conditions, including hydropower, commercial shipping, and the fishing industry.

---

# References {-}
1. Hughes, M. (2025, September 10). Practicum in Data Analysis. STA660, Miami University. <https://miamioh.instructure.com/courses/237421/pages/project-5-issues-and-resources?module_item_id=6017384>

2. R Core Team (2024). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.

3. Wickham, H., et al. (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686

4. Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York.

5. Hyndman, R. J., & Khandakar, Y. (2008). Automatic time series forecasting: the forecast package for R. Journal of Statistical Software, 27(3), 1–22. https://doi.org/10.18637/jss.v027.i03

6. Wickham, H., François, R., Henry, L., & Müller, K. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.4. https://CRAN.R-project.org/package=dplyr

7. Wickham, H., & Henry, L. (2023). tidyr: Tidy Messy Data. R package version 1.3.0. https://CRAN.R-project.org/package=tidyr

8. Grolemund, G., & Wickham, H. (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1–25. https://www.jstatsoft.org/v40/i03/

9. Wickham, H., & Hester, J. (2023). readr: Read Rectangular Text Data. R package version 2.1.4. https://CRAN.R-project.org/package=readr

10. Wickham, H. (2023). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.5.1. https://CRAN.R-project.org/package=stringr

11. Xie, Y. (2023). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.45.

12. Zhu, H. (2024). kableExtra: Construct Complex Table with 'kable' and Pipe Syntax. R package version 1.4.0. https://CRAN.R-project.org/package=kableExtra

13. Du, J., Kimball, J. S., Duguay, C., Kim, Y., & Watts, J. D. (2022). A 41-year (1979–2019) passive-microwave-derived lake ice phenology data record of the Northern Hemisphere. Earth System Science Data, 14(7), 3329–3351. https://doi.org/10.5194/essd-14-3329-2022

---

# Appendix {-}

```{r na_validation}
dat <- raw %>%
  mutate(row_id = row_number()) %>%
  pivot_longer(-c(day_mon, row_id), names_to = "year", values_to = "ice") %>%
  mutate(year = as.integer(year),
         ice  = suppressWarnings(as.numeric(ice))) %>%
  arrange(year, row_id)
# helper function to find mid-year NA runs
find_mid_na <- function(x, rows){
  w <- which(!is.na(x))
  if (length(w) == 0) return(tibble(start_row = integer(), end_row = integer()))
  first <- w[1]; last <- w[length(w)]
  z <- is.na(x[first:last]); if (!any(z)) return(tibble(start_row = integer(), end_row = integer()))
  r <- rle(z); ends <- cumsum(r$lengths); starts <- ends - r$lengths + 1
  idx <- which(r$values)
  tibble(start_row = rows[first:last][starts[idx]],
         end_row   = rows[first:last][ends[idx]])
}

# check the first non-NA row per year
starts <- dat %>%
  group_by(year) %>%
  summarise(first_data_row = min(row_id[!is.na(ice)], default = NA_integer_), .groups = "drop") %>%
  left_join(
    dat %>% filter(!is.na(ice)) %>%
      group_by(year) %>% slice_min(order_by = row_id, n = 1, with_ties = FALSE) %>%
      dplyr::select(year, first_day = day_mon),
    by = "year"
  ) %>%
  arrange(year)

# mid-year NA runs, which means how many runs of NAs between first and last non-NA
mid_runs <- dat %>%
  group_by(year) %>%
  reframe(find_mid_na(ice, row_id)) %>%                 
  left_join(dat %>% dplyr::select(year, row_id, day_mon),
            by = c("year","start_row" = "row_id")) %>%
  rename(start_day = day_mon) %>%
  left_join(dat %>% dplyr::select(year, row_id, day_mon),
            by = c("year","end_row" = "row_id")) %>%
  rename(end_day = day_mon) %>%
  mutate(n_days = end_row - start_row + 1) %>%
  arrange(year, start_row)

# summary of mid-year NAs
mid_summary <- mid_runs %>%
  group_by(year) %>%
  summarise(has_mid_NA = n() > 0,
            mid_NA_runs = n(),
            mid_NA_days = sum(n_days),
            .groups = "drop") %>%
  right_join(starts, by = "year") %>%
  arrange(year) %>%
  mutate(across(c(has_mid_NA, mid_NA_runs, mid_NA_days),
                ~ tidyr::replace_na(., 0)))

# show mid-year NA summary table using kable
mid_runs %>%
  kable("html", caption = "Appendix A: Mid-year NA Summary",
        col.names = c("Year", "Start Row", "End Row", "Start Day", "End Day", "Number of NAs")) %>%
  kable_styling(full_width = FALSE, position = "left", font_size = 12)
```

From this table, mid-year NAs are only the leap year Feb 29 rows, so imputation is only needed for leap year adjustment and leading/trailing NAs.

```{r acf_plot, fig.height=4}
# plot ACF of AUC time series
ggAcf(auc_data$AUC, lag.max = 20) +
  labs(title = "Appendix B",
       subtitle = "Autocorrelation Function (ACF) of Annual Ice Cover AUC Time Series") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold")
  )
```

The plot above displays the autocorrelation function for the annual cumulative ice cover (AUC) series. The vertical bars represent the correlation coefficients at various temporal lags, while the dashed blue lines indicate the 95% confidence intervals for white noise ($\pm 1.96/\sqrt{N}$). As observed, all autocorrelation coefficients fall well within the significance bounds. This lack of significant serial correlation suggests that the annual ice cover metrics are effectively independent from year to year. 




